{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.rendered_html { font-size: 18px; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Larger window and fontsize\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "display(HTML(\"<style>.rendered_html { font-size: 18px; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Sentiment Analysis refers to the use of text analysis and natural language processing to identify and extract subjective information in textual contents.\n",
    "\n",
    "In this practice we will focus on the analysis of the sentiment of a collection of tweets, applying some of the ideas that we have explored in class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "This corpus of tweets, developed by Sanfordâ€™s Natural Language processing research group.\n",
    "\n",
    "The training set is collected by querying Twitter API for happy emoticons like \":)\" and sad emoticons like \":(\" and labelling them positive or negative. The emoticons were then stripped and Re-Tweets and duplicates removed.\n",
    "\n",
    "The data is a CSV with emoticons removed. Data file format has 6 fields:\n",
    "\n",
    "    0 - the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive) **Note**: For the dataset there is only negative and positive tweets\n",
    "    1 - the id of the tweet (2087)\n",
    "    2 - the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "    3 - the query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "    4 - the user that tweeted (robotickilldozr)\n",
    "    5 - the text of the tweet (Lyx is cool)\n",
    "\n",
    "It also contains around 500 tweets manually collected and labelled for testing purposes.\n",
    "\n",
    "We randomly sample and use 5000 tweets from this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import csv\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "def loadDataset(in_file):\n",
    "    my_path = os.getcwd()\n",
    "    path = os.path.join(my_path, in_file)\n",
    "    column_names = ['sentiment','ID', 'Date', 'Query', 'user_id', 'tweet']\n",
    "    tweets = pd.read_csv(path, delimiter=',', quotechar='\"', header= None, names= column_names, encoding=\"ISO-8859-1\")\n",
    "\n",
    "    print('Readed ', len(tweets), \"tweets\")\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data and check the number of positive and negative tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Readed  1600000 tweets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "0    800000\n",
       "4    800000\n",
       "Name: ID, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_training_data = loadDataset(\"datasets/stanford_dataset/training.1600000.processed.noemoticon.csv\")\n",
    "raw_training_data.groupby('sentiment')['ID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset contains more than a million tweets, for our practice we will only use a sample of 5000 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Query</th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>939035</th>\n",
       "      <td>4</td>\n",
       "      <td>1793592465</td>\n",
       "      <td>Thu May 14 03:16:59 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>LilyFabia</td>\n",
       "      <td>day off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167371</th>\n",
       "      <td>0</td>\n",
       "      <td>1961652023</td>\n",
       "      <td>Fri May 29 09:50:07 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joshuamilane</td>\n",
       "      <td>@indysawhney seems like u r just pushing your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461470</th>\n",
       "      <td>0</td>\n",
       "      <td>2174457913</td>\n",
       "      <td>Sun Jun 14 22:35:37 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>LoclBandsRAwsom</td>\n",
       "      <td>Air fresheners that are supposed to smell like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190203</th>\n",
       "      <td>4</td>\n",
       "      <td>1983675734</td>\n",
       "      <td>Sun May 31 13:36:54 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Andematros</td>\n",
       "      <td>@lenanj http://twitpic.com/64re1 - Lena, the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476530</th>\n",
       "      <td>4</td>\n",
       "      <td>2066117107</td>\n",
       "      <td>Sun Jun 07 09:55:16 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Ravenpeach</td>\n",
       "      <td>@electricrocks AMEN AMEN AMEN!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment          ID                          Date     Query  \\\n",
       "939035           4  1793592465  Thu May 14 03:16:59 PDT 2009  NO_QUERY   \n",
       "167371           0  1961652023  Fri May 29 09:50:07 PDT 2009  NO_QUERY   \n",
       "461470           0  2174457913  Sun Jun 14 22:35:37 PDT 2009  NO_QUERY   \n",
       "1190203          4  1983675734  Sun May 31 13:36:54 PDT 2009  NO_QUERY   \n",
       "1476530          4  2066117107  Sun Jun 07 09:55:16 PDT 2009  NO_QUERY   \n",
       "\n",
       "                 user_id                                              tweet  \n",
       "939035         LilyFabia                                           day off   \n",
       "167371      joshuamilane  @indysawhney seems like u r just pushing your ...  \n",
       "461470   LoclBandsRAwsom  Air fresheners that are supposed to smell like...  \n",
       "1190203       Andematros  @lenanj http://twitpic.com/64re1 - Lena, the p...  \n",
       "1476530       Ravenpeach                   @electricrocks AMEN AMEN AMEN!    "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample 5000 tweets from the dataset\n",
    "training_data = raw_training_data.sample(n=5000)\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the distribution of positive and negative tweets remains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "0    2512\n",
       "4    2488\n",
       "Name: ID, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.groupby('sentiment')['ID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To facilitate the interpretation of the results we are going to recode the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Query</th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>939035</th>\n",
       "      <td>positive</td>\n",
       "      <td>1793592465</td>\n",
       "      <td>Thu May 14 03:16:59 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>LilyFabia</td>\n",
       "      <td>day off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167371</th>\n",
       "      <td>negative</td>\n",
       "      <td>1961652023</td>\n",
       "      <td>Fri May 29 09:50:07 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joshuamilane</td>\n",
       "      <td>@indysawhney seems like u r just pushing your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461470</th>\n",
       "      <td>negative</td>\n",
       "      <td>2174457913</td>\n",
       "      <td>Sun Jun 14 22:35:37 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>LoclBandsRAwsom</td>\n",
       "      <td>Air fresheners that are supposed to smell like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190203</th>\n",
       "      <td>positive</td>\n",
       "      <td>1983675734</td>\n",
       "      <td>Sun May 31 13:36:54 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Andematros</td>\n",
       "      <td>@lenanj http://twitpic.com/64re1 - Lena, the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476530</th>\n",
       "      <td>positive</td>\n",
       "      <td>2066117107</td>\n",
       "      <td>Sun Jun 07 09:55:16 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Ravenpeach</td>\n",
       "      <td>@electricrocks AMEN AMEN AMEN!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment          ID                          Date     Query  \\\n",
       "939035   positive  1793592465  Thu May 14 03:16:59 PDT 2009  NO_QUERY   \n",
       "167371   negative  1961652023  Fri May 29 09:50:07 PDT 2009  NO_QUERY   \n",
       "461470   negative  2174457913  Sun Jun 14 22:35:37 PDT 2009  NO_QUERY   \n",
       "1190203  positive  1983675734  Sun May 31 13:36:54 PDT 2009  NO_QUERY   \n",
       "1476530  positive  2066117107  Sun Jun 07 09:55:16 PDT 2009  NO_QUERY   \n",
       "\n",
       "                 user_id                                              tweet  \n",
       "939035         LilyFabia                                           day off   \n",
       "167371      joshuamilane  @indysawhney seems like u r just pushing your ...  \n",
       "461470   LoclBandsRAwsom  Air fresheners that are supposed to smell like...  \n",
       "1190203       Andematros  @lenanj http://twitpic.com/64re1 - Lena, the p...  \n",
       "1476530       Ravenpeach                   @electricrocks AMEN AMEN AMEN!    "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recode_sentiment(series):\n",
    "    if series == 4:\n",
    "        return 'positive'\n",
    "    else:\n",
    "        return 'negative'\n",
    "    \n",
    "training_data['sentiment'] = training_data['sentiment'].apply(recode_sentiment)\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet Preprocessing\n",
    "\n",
    "At this step, we will preprocess the text in the tweets, tokenize and stem it. We will have to take care of specific markups (e.g., hashtags) related to Twitter, as well as of aspects related to the sentiment analysis, like, for instance, emoticons.\n",
    "\n",
    "You may find interesting ideas in this regard in the following links:\n",
    " - Christopher Potts sentiment tokenizer: http://sentiment.christopherpotts.net/code-data/happyfuntokenizing.py\n",
    " - Brendan Oâ€™Connor twitter tokenizer: https://github.com/brendano/tweetmotif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashtags\n",
    "\n",
    "A hashtag is a word or an un-spaced phrase prefixed with the hash symbol (#). These are used to both naming subjects and phrases that are currently in trending topics. For example, #iPad, #news\n",
    "\n",
    "    Regular Expression: #(\\w+)\n",
    "\n",
    "    Replace Expression: HASH_hashtag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "hash_regex = re.compile(r\"#(\\w+)\")\n",
    "def hash_repl(match):\n",
    "\treturn '__HASH_'+match.group(1).upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happy midsummer everyone! My little brother has a bd today and here are few relatives having a dinner.. not so sure is it very nice and __HASH_HASHTAG'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "re.sub( hash_regex, hash_repl, 'happy midsummer everyone! My little brother has a bd today and here are few relatives having a dinner.. not so sure is it very nice and #hashtag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Names\n",
    "Every Twitter user has a unique username. Any thing directed towards that user can be indicated be writing their username preceded by â€˜@â€™. Thus, these are like proper nouns. For example, @Apple\n",
    "\n",
    "    Regular Expression: @(\\w+)\n",
    "\n",
    "    Replace Expression: user_username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_regex = re.compile(r\"@(\\w+)\")\n",
    "def user_repl(match):\n",
    "\treturn '__user_'+match.group(1).upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a __user_USERNAME'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "re.sub( user_regex, user_repl, 'This is a @username')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URLs\n",
    "Users often share hyperlinks in their tweets. Twitter shortens them using its in-house URL shortening service, like http://t.co/FCWXoUd8 - such links also enables Twitter to alert users if the link leads out of its domain. From the point of view of text classification, a particular URL is not important. However, presence of a URL can be an important feature. Regular expression for detecting a URL is fairly complex because of different types of URLs that can be there, but because of Twitterâ€™s shortening service, we can use a relatively simple regular expression.\n",
    "\n",
    "    Regular Expression: (http|https|ftp)://[a-zA-Z0-9\\\\./]+\n",
    "\n",
    "    Replace Expression: URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_regex = re.compile(r\"(http|https|ftp)://[a-zA-Z0-9\\./]+\")\n",
    "def url_repl(match):\n",
    "\treturn '__URL_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a __URL_'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "re.sub( url_regex, url_repl, 'This is a http://url.es')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emoticons\n",
    "\n",
    "Use of emoticons is very prevalent throughout the web, more so on micro-blogging sites. We identify the following emoticons and replace them with a single word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emoticons\n",
    "emoticons = \\\n",
    "\t[\t('__EMOT_SMILEY',\t[':-)', ':)', '(:', '(-:', ] )\t,\\\n",
    "\t\t('__EMOT_LAUGH',\t\t[':-D', ':D', 'X-D', 'XD', 'xD', ] )\t,\\\n",
    "\t\t('__EMOT_LOVE',\t\t['<3', ':\\*', ] )\t,\\\n",
    "\t\t('__EMOT_WINK',\t\t[';-)', ';)', ';-D', ';D', '(;', '(-;', ] )\t,\\\n",
    "\t\t('__EMOT_FROWN',\t\t[':-(', ':(', '(:', '(-:', ] )\t,\\\n",
    "\t\t('__EMOT_CRY',\t\t[':,(', ':\\'(', ':\"(', ':(('] )\t,\\\n",
    "\t]\n",
    "    \n",
    "def escape_paren(arr):\n",
    "\treturn [text.replace(')', '[)}\\]]').replace('(', '[({\\[]') for text in arr]\n",
    "\n",
    "def regex_union(arr):\n",
    "\treturn '(' + '|'.join( arr ) + ')'\n",
    "\n",
    "emoticons_regex = [ (repl, re.compile(regex_union(escape_paren(regx))) ) for (repl, regx) in emoticons ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a text with one emoticon  __EMOT_SMILEY  and another  __EMOT_FROWN \n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "text = \"This is a text with one emoticon :) and another :(\"\n",
    "for (repl, regx) in emoticons_regex :\n",
    "    text = re.sub(regx, ' '+repl+' ', text)\n",
    "    \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuations\n",
    "\n",
    "Although not all Punctuations are important from the point of view of classification but some of these, like question mark, exclamation mark can also provide information about the sentiments of the text. We replace every word boundary by a list of relevant punctuations present at that point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting by word boundaries\n",
    "word_bound_regex = re.compile(r\"\\W+\")\n",
    "\n",
    "# Punctuations\n",
    "punctuations = \\\n",
    "\t[\t#('',\t\t['.', ] )\t,\\\n",
    "\t\t#('',\t\t[',', ] )\t,\\\n",
    "\t\t#('',\t\t['\\'', '\\\"', ] )\t,\\\n",
    "\t\t('__PUNC_EXCL',\t\t['!', 'Â¡', ] )\t,\\\n",
    "\t\t('__PUNC_QUES',\t\t['?', 'Â¿', ] )\t,\\\n",
    "\t\t('__PUNC_ELLP',\t\t['...', 'â€¦', ] )\t,\\\n",
    "\t]\n",
    "\n",
    "#For punctuation replacement\n",
    "def punctuations_repl(match):\n",
    "\ttext = match.group(0)\n",
    "\trepl = []\n",
    "\tfor (key, parr) in punctuations :\n",
    "\t\tfor punc in parr :\n",
    "\t\t\tif punc in text:\n",
    "\t\t\t\trepl.append(key)\n",
    "\tif( len(repl)>0 ) :\n",
    "\t\treturn ' '+' '.join(repl)+' '\n",
    "\telse :\n",
    "\t\treturn ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This a text with an exclamation __PUNC_EXCL '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "re.sub( word_bound_regex , punctuations_repl, \"This a text with an exclamation!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repetitions\n",
    "People often use repeating characters while using colloquial language, like \"Iâ€™m in a hurrryyyyy\", \"We won, yaaayyyyy!\" As our final pre-processing step, we replace characters repeating more than twice as two characters.\n",
    "\n",
    "    Regular Expression: (.)\\1{1,}\n",
    "\n",
    "    Replace Expression: \\1\\1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeating words like hurrrryyyyyy\n",
    "rpt_regex = re.compile(r\"(.)\\1{1,}\", re.IGNORECASE);\n",
    "def rpt_repl(match):\n",
    "\treturn match.group(1)+match.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reppeated characters in wordss'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "re.sub( rpt_regex, rpt_repl, \"Reppppeated characters in wordsssssssss\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "\n",
    "We will now stemmize the words in the tweets by applying the Porter Stemmer seen in class. This stemmer was very widely used and became and remains the de facto standard algorithm used for English stemming. It offers excellent trade-off between speed, readability, and accuracy.\n",
    "\n",
    "NLTK has its own implementation of the stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'textual represent contain word appli the porter stemmer'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "text = \"Textual representation containing words to apply the porter stemmer\"\n",
    "text = [word if(word[0:2]=='__') else word.lower() for word in text.split() if len(word) >= 3]\n",
    "text = [stemmer.stem(w) for w in text]                \n",
    "text = \" \".join(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper function that encloses all the processing procedures\n",
    "def processAll(text):\n",
    "    \n",
    "    text = re.sub( hash_regex, hash_repl, text )\n",
    "    text = re.sub( user_regex, user_repl, text)\n",
    "    text = re.sub( url_regex, ' __URL ', text )\n",
    "    \n",
    "    for (repl, regx) in emoticons_regex :\n",
    "        text = re.sub(regx, ' '+repl+' ', text)\n",
    "    \n",
    "    text = text.replace('\\'','')\n",
    "    \n",
    "    text = re.sub( word_bound_regex , punctuations_repl, text )\n",
    "    text = re.sub( rpt_regex, rpt_repl, text )\n",
    "    \n",
    "        \n",
    "    text = [word if(word[0:2]=='__') else word.lower() for word in text.split() if len(word) >= 3]\n",
    "    text = [stemmer.stem(w) for w in text]                \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a new column in our dataframe with the processed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Query</th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>processed_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>939035</th>\n",
       "      <td>positive</td>\n",
       "      <td>1793592465</td>\n",
       "      <td>Thu May 14 03:16:59 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>LilyFabia</td>\n",
       "      <td>day off</td>\n",
       "      <td>[day, off]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167371</th>\n",
       "      <td>negative</td>\n",
       "      <td>1961652023</td>\n",
       "      <td>Fri May 29 09:50:07 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joshuamilane</td>\n",
       "      <td>@indysawhney seems like u r just pushing your ...</td>\n",
       "      <td>[__user_indysawhney, seem, like, just, push, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461470</th>\n",
       "      <td>negative</td>\n",
       "      <td>2174457913</td>\n",
       "      <td>Sun Jun 14 22:35:37 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>LoclBandsRAwsom</td>\n",
       "      <td>Air fresheners that are supposed to smell like...</td>\n",
       "      <td>[air, freshen, that, are, suppos, smell, like,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190203</th>\n",
       "      <td>positive</td>\n",
       "      <td>1983675734</td>\n",
       "      <td>Sun May 31 13:36:54 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Andematros</td>\n",
       "      <td>@lenanj http://twitpic.com/64re1 - Lena, the p...</td>\n",
       "      <td>[__user_lenanj, __url, lena, the, pictur, you,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476530</th>\n",
       "      <td>positive</td>\n",
       "      <td>2066117107</td>\n",
       "      <td>Sun Jun 07 09:55:16 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Ravenpeach</td>\n",
       "      <td>@electricrocks AMEN AMEN AMEN!</td>\n",
       "      <td>[__user_electricrock, amen, amen, amen, __punc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment          ID                          Date     Query  \\\n",
       "939035   positive  1793592465  Thu May 14 03:16:59 PDT 2009  NO_QUERY   \n",
       "167371   negative  1961652023  Fri May 29 09:50:07 PDT 2009  NO_QUERY   \n",
       "461470   negative  2174457913  Sun Jun 14 22:35:37 PDT 2009  NO_QUERY   \n",
       "1190203  positive  1983675734  Sun May 31 13:36:54 PDT 2009  NO_QUERY   \n",
       "1476530  positive  2066117107  Sun Jun 07 09:55:16 PDT 2009  NO_QUERY   \n",
       "\n",
       "                 user_id                                              tweet  \\\n",
       "939035         LilyFabia                                           day off    \n",
       "167371      joshuamilane  @indysawhney seems like u r just pushing your ...   \n",
       "461470   LoclBandsRAwsom  Air fresheners that are supposed to smell like...   \n",
       "1190203       Andematros  @lenanj http://twitpic.com/64re1 - Lena, the p...   \n",
       "1476530       Ravenpeach                   @electricrocks AMEN AMEN AMEN!     \n",
       "\n",
       "                                           processed_tweet  \n",
       "939035                                          [day, off]  \n",
       "167371   [__user_indysawhney, seem, like, just, push, y...  \n",
       "461470   [air, freshen, that, are, suppos, smell, like,...  \n",
       "1190203  [__user_lenanj, __url, lena, the, pictur, you,...  \n",
       "1476530  [__user_electricrock, amen, amen, amen, __punc...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['processed_tweet'] = training_data.tweet.apply(processAll)\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Creation\n",
    "\n",
    "A wide variety of features can be used to build a classifier for tweets. The most widely used and basic feature set is word n-grams. However, there's a lot of domain specific information present in tweets that can also be used for classifying them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigrams\n",
    "\n",
    "Unigrams are the simplest features that can be used for text classification. A Tweet can be represented by a multiset of words present in it. We, however, have used the presence of unigrams in a tweet as a feature set. Presence of a word is more important than how many times it is repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'Example': 1, 'of': 1, 'tweet': 1, 'represented': 1, 'as': 1, 'unigrams': 1})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [\"Example\", \"of\", \"tweet\", \"represented\", \"as\", \"unigrams\"]\n",
    "\n",
    "unigrams_fd = nltk.FreqDist()\n",
    "unigrams_fd.update(text)\n",
    "unigrams_fd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-grams\n",
    "\n",
    "N-gram refers to an n-long sequence of words. Probabilistic Language Models based on Unigrams, Bigrams and Trigrams can be successfully used to predict the next word given a current context of words. In the domain of sentiment analysis, the performance of N-grams is unclear.\n",
    "\n",
    "As the order of the n-grams increases, they tend to be more and more sparse. Let's then try bi-gram and tri-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'Example,of': 1, 'of,tweet': 1, 'tweet,represented': 1, 'represented,as': 1, 'as,unigrams': 1})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bigrams\n",
    "words_bi  = [ ','.join(map(str,bg)) for bg in nltk.bigrams(text) ]\n",
    "bi_grams_fd = nltk.FreqDist()\n",
    "bi_grams_fd.update( words_bi )\n",
    "bi_grams_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'Example,of,tweet': 1, 'of,tweet,represented': 1, 'tweet,represented,as': 1, 'represented,as,unigrams': 1})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trigrams\n",
    "words_tri  = [ ','.join(map(str,tg)) for tg in nltk.trigrams(text) ]\n",
    "tri_grams_fd = nltk.FreqDist()\n",
    "tri_grams_fd.update( words_tri )\n",
    "tri_grams_fd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the bigrams and trigrams models for the processed text in the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper function that encloses all the n-grams procedures\n",
    "\n",
    "def get_word_features(words):\n",
    "    bag = {}\n",
    "    words_uni = [ 'has(%s)'% ug for ug in words ]\n",
    "    words_bi  = [ 'has(%s)'% ','.join(map(str,bg)) for bg in nltk.bigrams(words) ]\n",
    "    words_tri = [ 'has(%s)'% ','.join(map(str,tg)) for tg in nltk.trigrams(words) ]\n",
    "    \n",
    "    for f in words_uni+words_bi+words_tri:\n",
    "        bag[f] = 1\n",
    "\n",
    "    return bag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negations\n",
    "\n",
    "The need negation detection in sentiment analysis can be illustrated by the difference in the meaning of the phrases, \"This is good\" vs. \"This is not good\" However, the negations occurring in natural language are seldom so simple. Handling the negation consists of two tasks â€“ Detection of explicit negation cues and the scope of negation of these words.\n",
    "\n",
    "**Scope of Negation**\n",
    "\n",
    "Words immediately preceding and following the negation cues are the most negative and the words that come farther away do not lie in the scope of negation of such cues. We define left and right negativity of a word as the chances that meaning of that word is actually the opposite. Left negativity depends on the closest negation cue on the left and similarly for Right negativity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "negtn_regex = re.compile( r\"\"\"(?:\n",
    "    ^(?:never|no|nothing|nowhere|noone|none|not|\n",
    "        havent|hasnt|hadnt|cant|couldnt|shouldnt|\n",
    "        wont|wouldnt|dont|doesnt|didnt|isnt|arent|aint\n",
    "    )$\n",
    ")\n",
    "|\n",
    "n't\n",
    "\"\"\", re.X)\n",
    "\n",
    "def get_negation_features(words):\n",
    "    INF = 0.0\n",
    "    negtn = [ bool(negtn_regex.search(w)) for w in words ]\n",
    "\n",
    "    left = [0.0] * len(words)\n",
    "    prev = 0.0\n",
    "    for i in range(0,len(words)):\n",
    "        if( negtn[i] ):\n",
    "            prev = 1.0\n",
    "        left[i] = prev\n",
    "        prev = max( 0.0, prev-0.1)\n",
    "\n",
    "    right = [0.0] * len(words)\n",
    "    prev = 0.0\n",
    "    for i in reversed(range(0,len(words))):\n",
    "        if( negtn[i] ):\n",
    "            prev = 1.0\n",
    "        right[i] = prev\n",
    "        prev = max( 0.0, prev-0.1)\n",
    "\n",
    "    return dict( zip(\n",
    "                    ['neg_l('+w+')' for w in  words] + ['neg_r('+w+')' for w in  words],\n",
    "                    left + right ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg_l(This)': 0.0,\n",
       " 'neg_l(text)': 0.0,\n",
       " 'neg_l(does)': 0.0,\n",
       " 'neg_l(not)': 1.0,\n",
       " 'neg_l(have)': 0.9,\n",
       " 'neg_l(a)': 0.8,\n",
       " 'neg_l(negation)': 0.7000000000000001,\n",
       " 'neg_r(This)': 0.7000000000000001,\n",
       " 'neg_r(text)': 0.8,\n",
       " 'neg_r(does)': 0.9,\n",
       " 'neg_r(not)': 1.0,\n",
       " 'neg_r(have)': 0.0,\n",
       " 'neg_r(a)': 0.0,\n",
       " 'neg_r(negation)': 0.0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "text = [\"This\",\"text\", \"does\", \"not\", \"have\", \"a\", \"negation\"]\n",
    "get_negation_features(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging\n",
    "\n",
    "With POS Tagging we can get the category of each word. Some of these categories are more interesting in order to infer the sentiment of given tweet. For example, adjectives are expected to carry most sentiment information than adverbs. In a similar way, some particular names can carry a positive or negative implication for particular domains.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_features(words):\n",
    "    tags = {}\n",
    "    tagged_words = [ 'has(%s)'% w+'_'+tag for w,tag in nltk.pos_tag(words)]\n",
    "    \n",
    "    for tw in tagged_words:\n",
    "        tags[tw] = 1\n",
    "\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous step, let's create an function to apply all these creation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper function for the extraction of features\n",
    "def extract_features(text):\n",
    "    features = {}\n",
    "    \n",
    "    words = processAll(text)\n",
    "\n",
    "    word_features = get_word_features(words)\n",
    "    features.update( word_features )\n",
    "\n",
    "    negation_features = get_negation_features(words)\n",
    "    features.update( negation_features )\n",
    "    \n",
    "#     pos_features = get_pos_features(words)\n",
    "#     features.update( pos_features )\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>processed_tweet_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>939035</th>\n",
       "      <td>day off</td>\n",
       "      <td>{'has(day)': 1, 'has(off)': 1, 'has(day,off)':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167371</th>\n",
       "      <td>@indysawhney seems like u r just pushing your ...</td>\n",
       "      <td>{'has(__user_indysawhney)': 1, 'has(seem)': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461470</th>\n",
       "      <td>Air fresheners that are supposed to smell like...</td>\n",
       "      <td>{'has(air)': 1, 'has(freshen)': 1, 'has(that)'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190203</th>\n",
       "      <td>@lenanj http://twitpic.com/64re1 - Lena, the p...</td>\n",
       "      <td>{'has(__user_lenanj)': 1, 'has(__url)': 1, 'ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476530</th>\n",
       "      <td>@electricrocks AMEN AMEN AMEN!</td>\n",
       "      <td>{'has(__user_electricrock)': 1, 'has(amen)': 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     tweet  \\\n",
       "939035                                            day off    \n",
       "167371   @indysawhney seems like u r just pushing your ...   \n",
       "461470   Air fresheners that are supposed to smell like...   \n",
       "1190203  @lenanj http://twitpic.com/64re1 - Lena, the p...   \n",
       "1476530                   @electricrocks AMEN AMEN AMEN!     \n",
       "\n",
       "                                  processed_tweet_features  \n",
       "939035   {'has(day)': 1, 'has(off)': 1, 'has(day,off)':...  \n",
       "167371   {'has(__user_indysawhney)': 1, 'has(seem)': 1,...  \n",
       "461470   {'has(air)': 1, 'has(freshen)': 1, 'has(that)'...  \n",
       "1190203  {'has(__user_lenanj)': 1, 'has(__url)': 1, 'ha...  \n",
       "1476530  {'has(__user_electricrock)': 1, 'has(amen)': 1...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['processed_tweet_features'] = training_data.tweet.apply(extract_features)\n",
    "training_data[['tweet','processed_tweet_features']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "Let's now use the processed tweet features to create a classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training-test Splitting\n",
    "\n",
    "To evaluate our approaches, we are going to split our data into train and validation. We will use the train to create the models and the validation to validate their performance. Once we have selected the best model (according to the accuracy on the validation set) we can use this model to predict our test set.\n",
    "\n",
    "In this way, test set will remain as unseen data for all the process: we are not going to make any decision based on the test error. Therefore, we can assume that the results on the test set will be the same that we will obtain when new unseen data appears in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = 4000\n",
    "train_tweets = [(tweet, sentiment) for tweet, sentiment in training_data[['tweet', 'sentiment']].values[:training_size]]\n",
    "validation_tweets  = [(tweet, sentiment) for tweet, sentiment in training_data[['tweet', 'sentiment']].values[training_size:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data for the classifier\n",
    "\n",
    "We have previously defined a feature extraction process, which we have wrapped into the `extract_features` function. By making use of the `nltk.classify.apply_features` function provided by NLTK, we will process the tweets and create the features that will be used for the classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the data processing and cleaning extraction methodologies\n",
    "v_train = nltk.classify.apply_features(extract_features,train_tweets)\n",
    "v_validation  = nltk.classify.apply_features(extract_features,validation_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the resultant object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the tweet =  day off \n",
      " \n",
      "The following features has been created:\n",
      " \n",
      "{'has(day)': 1, 'has(off)': 1, 'has(day,off)': 1, 'neg_l(day)': 0.0, 'neg_l(off)': 0.0, 'neg_r(day)': 0.0, 'neg_r(off)': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"For the tweet = \", training_data.tweet.values[0])\n",
    "print(\" \")\n",
    "print(\"The following features has been created:\")\n",
    "print(\" \")\n",
    "print(v_train[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "We will start with a simple NaÃ¯ve Bayes Classifier. For a given tweet, if we need to find the label for it, we find the probabilities of all the labels, given that feature and then select the label with maximum probability.\n",
    "\n",
    "NLTK has its own implementation of Naive Bayes `nltk.classify.NaiveBayesClassifier`. If you prefer, you can use the Naive Bayes implementation in `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = nltk.classify.NaiveBayesClassifier\n",
    "nb_class = nb_classifier.train(v_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "\n",
    "Let's evaluate the accuracy of our model in our validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model =  0.711\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the model = \", nltk.classify.accuracy(nb_class, v_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "73 % of accuracy seems pretty good for the task.\n",
    "\n",
    "We can have a more detailed idea of the performance by taking a look to the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "         |   n   p |\n",
      "         |   e   o |\n",
      "         |   g   s |\n",
      "         |   a   i |\n",
      "         |   t   t |\n",
      "         |   i   i |\n",
      "         |   v   v |\n",
      "         |   e   e |\n",
      "---------+---------+\n",
      "negative |<351>149 |\n",
      "positive | 140<360>|\n",
      "---------+---------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build confusion matrix over validation set\n",
    "test_truth   = [s for (t,s) in v_validation]\n",
    "test_predict = [nb_class.classify(t) for (t,s) in v_validation]\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print()\n",
    "print(nltk.ConfusionMatrix( test_truth, test_predict ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most Representative Features\n",
    "\n",
    "The NLTK classifier object allows us to see the most representative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "              neg_l(sad) = 0.0            negati : positi =     22.3 : 1.0\n",
      "                has(sad) = 1              negati : positi =     17.6 : 1.0\n",
      "              neg_r(sad) = 0.0            negati : positi =     14.5 : 1.0\n",
      "          has(thank,you) = 1              positi : negati =     13.2 : 1.0\n",
      "             neg_l(hurt) = 0.0            negati : positi =     12.4 : 1.0\n",
      "             neg_r(hurt) = 0.0            negati : positi =     12.1 : 1.0\n",
      "          has(dont,have) = 1              negati : positi =     11.5 : 1.0\n",
      "            neg_r(still) = 0.9            negati : positi =     10.2 : 1.0\n",
      "                has(die) = 1              negati : positi =     10.2 : 1.0\n",
      "              neg_r(dad) = 0.0            negati : positi =      9.6 : 1.0\n",
      "             neg_l(find) = 0.9            negati : positi =      9.6 : 1.0\n",
      "              neg_l(die) = 0.0            negati : positi =      9.6 : 1.0\n",
      "               has(wont) = 1              negati : positi =      9.5 : 1.0\n",
      "             neg_l(wont) = 1.0            negati : positi =      9.5 : 1.0\n",
      "             neg_r(wont) = 1.0            negati : positi =      9.5 : 1.0\n",
      "               has(hurt) = 1              negati : positi =      9.2 : 1.0\n",
      "             neg_l(work) = 0.9            negati : positi =      8.9 : 1.0\n",
      "              has(wasnt) = 1              negati : positi =      8.9 : 1.0\n",
      "            neg_l(wasnt) = 0.0            negati : positi =      8.9 : 1.0\n",
      "            neg_l(wanna) = 0.9            negati : positi =      8.2 : 1.0\n",
      "              neg_l(boo) = 0.0            negati : positi =      8.2 : 1.0\n",
      "            neg_r(wasnt) = 0.0            negati : positi =      8.2 : 1.0\n",
      "              has(broke) = 1              negati : positi =      8.2 : 1.0\n",
      "           has(internet) = 1              negati : positi =      8.2 : 1.0\n",
      "              has(hello) = 1              positi : negati =      7.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "nb_class.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "\n",
    "We have applied a thorough process to create features for our tweets. However, is it justified? Have we actually created a better representation of our data? To know that, we are going to create a baseline model that uses only the text in the tweets (with no features added).\n",
    "\n",
    "To that end we define a new extraction function that only extract the terms from the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_train_tweets = [(tweet.split(\" \"), sentiment) for tweet, sentiment in training_data[['tweet', 'sentiment']].values[:training_size]]\n",
    "baseline_validation_tweets  = [(tweet.split(\" \"), sentiment) for tweet, sentiment in training_data[['tweet', 'sentiment']].values[training_size:]]\n",
    "\n",
    "# Wrapper function for the extraction of features\n",
    "def extract_baseline_features(words):\n",
    "    \n",
    "    bag = {}\n",
    "    words_uni = [ 'has(%s)'% ug for ug in words ]\n",
    "    \n",
    "    for f in words_uni:\n",
    "        bag[f] = 1\n",
    "\n",
    "    return bag\n",
    "\n",
    "v_baseline_train = nltk.classify.apply_features(extract_baseline_features, baseline_train_tweets)\n",
    "v_baseline_validation = nltk.classify.apply_features(extract_baseline_features, baseline_validation_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit a new naive based classifier over this baseline representation and evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_nb_classifier = nltk.classify.NaiveBayesClassifier\n",
    "baseline_nb_class = nb_classifier.train(v_baseline_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the baseline model =  0.693\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the baseline model = \", nltk.classify.accuracy(baseline_nb_class, v_baseline_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "         |   n   p |\n",
      "         |   e   o |\n",
      "         |   g   s |\n",
      "         |   a   i |\n",
      "         |   t   t |\n",
      "         |   i   i |\n",
      "         |   v   v |\n",
      "         |   e   e |\n",
      "---------+---------+\n",
      "negative |<318>182 |\n",
      "positive | 194<306>|\n",
      "---------+---------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build confusion matrix over validation set\n",
    "test_truth   = [s for (t,s) in v_baseline_validation]\n",
    "test_predict = [nb_class.classify(t) for (t,s) in v_baseline_validation]\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print()\n",
    "print(nltk.ConfusionMatrix( test_truth, test_predict ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, performance is significantly lower than that of the model using all the features we have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                has(sad) = 1              negati : positi =     17.2 : 1.0\n",
      "              has(sucks) = 1              negati : positi =     10.2 : 1.0\n",
      "            has(awesome) = 1              positi : negati =      9.9 : 1.0\n",
      "              has(won't) = 1              negati : positi =      9.3 : 1.0\n",
      "                has(Had) = 1              positi : negati =      8.4 : 1.0\n",
      "              has(broke) = 1              negati : positi =      8.2 : 1.0\n",
      "                has(dad) = 1              negati : positi =      8.2 : 1.0\n",
      "              has(home.) = 1              negati : positi =      8.2 : 1.0\n",
      "               has(They) = 1              negati : positi =      7.6 : 1.0\n",
      "              has(bored) = 1              negati : positi =      7.6 : 1.0\n",
      "               has(poor) = 1              negati : positi =      7.6 : 1.0\n",
      "             has(wasn't) = 1              negati : positi =      7.6 : 1.0\n",
      "              has(sorry) = 1              negati : positi =      7.6 : 1.0\n",
      "               has(you?) = 1              positi : negati =      7.1 : 1.0\n",
      "             has(boring) = 1              negati : positi =      6.9 : 1.0\n",
      "                 has(ya) = 1              positi : negati =      6.3 : 1.0\n",
      "                has(Too) = 1              negati : positi =      6.3 : 1.0\n",
      "           has(computer) = 1              negati : positi =      6.3 : 1.0\n",
      "             has(scared) = 1              negati : positi =      6.3 : 1.0\n",
      "               has(wont) = 1              negati : positi =      6.3 : 1.0\n",
      "               has(full) = 1              positi : negati =      5.7 : 1.0\n",
      "                has(wow) = 1              positi : negati =      5.7 : 1.0\n",
      "              has(hurts) = 1              negati : positi =      5.7 : 1.0\n",
      "            has(missing) = 1              negati : positi =      5.7 : 1.0\n",
      "             has(office) = 1              negati : positi =      5.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Most Representative Features\n",
    "baseline_nb_class.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxEnt Classifier\n",
    "\n",
    "Let's try a more sophisticated classifier to see if we can boost the classification performance. In particular we will apply a Maximum Entropy Classifier. \n",
    "\n",
    "\n",
    "This classifier works by finding a probability distribution that maximizes the likelihood of testable data. This probability function is parameterized by weight vector. The optimal value of which can be found out using the method of Lagrange multipliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (5 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.497\n",
      "             2          -0.69303        0.991\n",
      "             3          -0.69291        0.991\n",
      "             4          -0.69279        0.991\n",
      "         Final          -0.69267        0.991\n"
     ]
    }
   ],
   "source": [
    "max_ent_classifier = nltk.classify.MaxentClassifier\n",
    "max_ent_class = max_ent_classifier.train(v_train, algorithm='GIS', max_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model =  0.722\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the model = \", nltk.classify.accuracy(max_ent_class, v_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "         |   n   p |\n",
      "         |   e   o |\n",
      "         |   g   s |\n",
      "         |   a   i |\n",
      "         |   t   t |\n",
      "         |   i   i |\n",
      "         |   v   v |\n",
      "         |   e   e |\n",
      "---------+---------+\n",
      "negative |<354>146 |\n",
      "positive | 132<368>|\n",
      "---------+---------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build confusion matrix over validation set\n",
    "test_truth   = [s for (t,s) in v_validation]\n",
    "test_predict = [max_ent_class.classify(t) for (t,s) in v_validation]\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print()\n",
    "print(nltk.ConfusionMatrix( test_truth, test_predict ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is similar than the one of Naive Bayes. If we review the most informative terms, we can see that both algorithms focus on similar features to perform the final classification; hence the similar performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -0.000 neg_l(sad)==0.0 and label is 'positive'\n",
      "  -0.000 has(sad)==1 and label is 'positive'\n",
      "  -0.000 neg_r(sad)==0.0 and label is 'positive'\n",
      "  -0.000 has(dont,have)==1 and label is 'positive'\n",
      "  -0.000 has(thank,you)==1 and label is 'negative'\n",
      "  -0.000 neg_l(hurt)==0.0 and label is 'positive'\n",
      "  -0.000 neg_r(hurt)==0.0 and label is 'positive'\n",
      "  -0.000 has(die)==1 and label is 'positive'\n",
      "  -0.000 neg_r(still)==0.9 and label is 'positive'\n",
      "  -0.000 neg_l(die)==0.0 and label is 'positive'\n",
      "  -0.000 neg_l(find)==0.9 and label is 'positive'\n",
      "  -0.000 neg_r(dad)==0.0 and label is 'positive'\n",
      "  -0.000 has(wasnt)==1 and label is 'positive'\n",
      "  -0.000 neg_l(wasnt)==0.0 and label is 'positive'\n",
      "  -0.000 neg_l(work)==0.9 and label is 'positive'\n",
      "  -0.000 neg_l(boo)==0.0 and label is 'positive'\n",
      "  -0.000 has(broke)==1 and label is 'positive'\n",
      "  -0.000 neg_l(wanna)==0.9 and label is 'positive'\n",
      "  -0.000 neg_r(wasnt)==0.0 and label is 'positive'\n",
      "  -0.000 has(internet)==1 and label is 'positive'\n",
      "  -0.000 has(you,all)==1 and label is 'negative'\n",
      "  -0.000 neg_r(broke)==0.0 and label is 'positive'\n",
      "  -0.000 neg_r(die)==0.0 and label is 'positive'\n",
      "  -0.000 has(thank,__punc_excl)==1 and label is 'negative'\n",
      "  -0.000 has(hello)==1 and label is 'negative'\n"
     ]
    }
   ],
   "source": [
    "max_ent_class.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SentiWordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the theoretical session we presented some sentiment resources that could be used to enrich our dataset with external information.\n",
    "\n",
    "In particular, SentiWordNet provides a sentiment annotation for the WordNet synsets. We can add this sentiment annotation as new features to our dataset. \n",
    "\n",
    "In the following, we define a fuction that based on the words in the tweets and their POS tagging, find the sentiment annotation for the word_POS_TAG in SentiWordNet. We then add these values as new features in our dataset and use them to train a new MaxEnt Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\madcastea\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     C:\\Users\\madcastea\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download the Wordnet Corpus\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Download the Senti Wordnet Corpus\n",
    "nltk.download('sentiwordnet')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    " \n",
    "lemmatizer = WordNetLemmatizer()\n",
    " \n",
    "def penn_to_wn(tag):\n",
    "    \"\"\"\n",
    "    Convert between the PennTreebank tags to simple Wordnet tags\n",
    "    \"\"\"\n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    return None\n",
    " \n",
    "\n",
    "def swn_polarity(text):\n",
    "    sentiment = 0.0\n",
    "    tokens_count = 0\n",
    "  \n",
    "    tagged_sentence = pos_tag(word_tokenize(text))\n",
    "    sentiment = {}\n",
    "    for word, tag in tagged_sentence:\n",
    "        \n",
    "        wn_tag = penn_to_wn(tag)\n",
    "        if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV):\n",
    "            sentiment[\"sent(\"+word+\")\"] = 0.0\n",
    "            continue\n",
    "        \n",
    "        lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "        if not lemma:\n",
    "            sentiment[\"sent(\"+word+\")\"] = 0.0\n",
    "            continue\n",
    "\n",
    "        synsets = wn.synsets(lemma, pos=wn_tag)\n",
    "        if not synsets:\n",
    "            sentiment[\"sent(\"+word+\")\"] = 0.0\n",
    "            continue\n",
    "\n",
    "        # Take the first sense, the most common\n",
    "        synset = synsets[0]\n",
    "        swn_synset = swn.senti_synset(synset.name())\n",
    "\n",
    "        sentiment[\"sent(\"+word+\")\"] = swn_synset.pos_score() - swn_synset.neg_score()\n",
    "        \n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sent(This)': 0.0,\n",
       " 'sent(is)': 0.0,\n",
       " 'sent(a)': 0.0,\n",
       " 'sent(text)': 0.0,\n",
       " 'sent(with)': 0.0,\n",
       " 'sent(good)': 0.75,\n",
       " 'sent(and)': 0.0,\n",
       " 'sent(very)': 0.0,\n",
       " 'sent(words)': 0.0,\n",
       " 'sent(bad)': -0.625,\n",
       " 'sent(stupid)': -0.75}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This is a text with good and very good words and bad and stupid words\"\n",
    "swn_polarity(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This annotation provides a sentiment score (based on the SentiWordNet sentiment score) for each term in the tweets (-1 negative, 1 positive, 0 neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper function for the extraction of features + sentiment features\n",
    "def extract_features_with_sentiment(text):\n",
    "    features = {}\n",
    "    \n",
    "    words = processAll(text)\n",
    "    \n",
    "    sentiment_features = swn_polarity(text)\n",
    "    features.update(sentiment_features)\n",
    "    \n",
    "    word_features = get_word_features(words)\n",
    "    features.update( word_features )\n",
    "\n",
    "    negation_features = get_negation_features(words)\n",
    "    features.update( negation_features )\n",
    "        \n",
    "    pos_features = get_pos_features(words)\n",
    "    features.update( pos_features )\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the data processing and cleaning extraction methodologies\n",
    "v_train_sentiment = nltk.classify.apply_features(extract_features_with_sentiment,train_tweets)\n",
    "v_validation_sentiment  = nltk.classify.apply_features(extract_features_with_sentiment,validation_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a new classfier with the sentiment features\n",
    "max_ent_classifier = nltk.classify.MaxentClassifier\n",
    "max_ent_class = max_ent_classifier.train(v_train_sentiment, algorithm='GIS', max_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of the model = \", nltk.classify.accuracy(max_ent_class, v_validation_sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build confusion matrix over validation set\n",
    "test_truth   = [s for (t,s) in v_validation_sentiment]\n",
    "test_predict = [max_ent_class.classify(t) for (t,s) in v_validation_sentiment]\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print()\n",
    "print(nltk.ConfusionMatrix( test_truth, test_predict ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have improve the accuracy of our classifier by including the sentiment information of the terms.\n",
    "\n",
    "If we take a look to the most informative features, we can find some sentiment-related features among them. For instance, `sad` has a negative implication, codified by the feature: `sent(sad)==-0.625`, which is highly informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ent_class.show_most_informative_features(25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
